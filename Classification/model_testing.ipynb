{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from RSRTxReadBin.RTxReadBin import RTxReadBin\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, path = \"waveforms_r6p8_fast/\", file_list=[], ch=0, n_mels=64, n_fft=2048, hop_length=512):\n",
    "        self.file_list = file_list\n",
    "        self.ch = ch\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.path = path\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = self.load_waveform(file_path, self.ch)\n",
    "        mel_spectrogram = self.transform_audio(waveform, sample_rate) # No use the spectrogram\n",
    "        label = self.get_label_from_filename(file_path)\n",
    "        return waveform, label\n",
    "\n",
    "    def load_waveform(self, file_path, ch):\n",
    "        wfm_data, b, meta_data = RTxReadBin(self.path+file_path, nNofChannels=2)\n",
    "        wfm_data = np.array(wfm_data[:, 0, ch])[:int(len(wfm_data[:, 0, ch]) / 2)]\n",
    "        sample_rate = int(1 / meta_data[\"Resolution\"])\n",
    "        waveform = torch.from_numpy(wfm_data).float()\n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def transform_audio(self, waveform, sample_rate):\n",
    "        transform = transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=self.n_mels, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        mel_spectrogram = transform(waveform.unsqueeze(0))\n",
    "        return mel_spectrogram\n",
    "\n",
    "    def get_label_from_filename(self, filename):\n",
    "        return int(os.path.basename(filename).split('_')[0])\n",
    "\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=10, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.pool1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        #print(x.shape)\n",
    "        x = x.squeeze(0)\n",
    "        #print(x.shape)\n",
    "        return F.log_softmax(x)\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ARB r2p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (1025) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8367\n",
      "Running MTJ r2p3\n",
      "Accuracy: 0.7767\n",
      "Running ARB r6p7\n",
      "Accuracy: 0.8233\n",
      "Running MTJ r6p7\n",
      "Accuracy: 0.8400\n",
      "Running ARB r6p8\n",
      "Accuracy: 0.6867\n",
      "Running MTJ r6p8\n",
      "Accuracy: 0.8100\n",
      "Running ARB r6p9\n",
      "Accuracy: 0.8833\n",
      "Running MTJ r6p9\n",
      "Accuracy: 0.8967\n",
      "Running ARB r1p9\n",
      "Accuracy: 0.8300\n",
      "Running MTJ r1p9\n",
      "Accuracy: 0.6267\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    return accuracy\n",
    "\n",
    "sample = [\"r2p3\", \"r6p7\", \"r6p8\",\"r6p9\",\"r1p9\"]\n",
    "arb = False\n",
    "\n",
    "\n",
    "for m in sample:\n",
    "    for arb in [True,False]:\n",
    "    # load model\n",
    "        if arb:\n",
    "            channel = 1\n",
    "            model = torch.load(f\"CNN_filter_{m}_softmax_arb.pt\", map_location=torch.device('cpu'))\n",
    "            print(f\"Running ARB {m}\")\n",
    "        else:\n",
    "            channel = 0\n",
    "            model = torch.load(f\"CNN_filter_{m}_softmax.pt\", map_location=torch.device('cpu'))\n",
    "            print(f\"Running MTJ {m}\")\n",
    "\n",
    "        path = f\"waveforms_{m}_fast_test/\"\n",
    "\n",
    "        file_list = os.listdir(path)\n",
    "        file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "        dataset = SpeechDataset(path = path, file_list=file_list, ch=channel)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "        test_model(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ARB r2p3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lasse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (1025) may be set too low.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lasse\\AppData\\Local\\Temp/ipykernel_24108/2981074007.py:106: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7067\n",
      "Running MTJ r2p3\n",
      "Accuracy: 0.5467\n",
      "Running ARB r6p7\n",
      "Accuracy: 0.6967\n",
      "Running MTJ r6p7\n",
      "Accuracy: 0.4833\n",
      "Running ARB r6p8\n",
      "Accuracy: 0.7200\n",
      "Running MTJ r6p8\n",
      "Accuracy: 0.5467\n",
      "Running ARB r6p9\n",
      "Accuracy: 0.5933\n",
      "Running MTJ r6p9\n",
      "Accuracy: 0.5567\n",
      "Running ARB r1p9\n",
      "Accuracy: 0.5233\n",
      "Running MTJ r1p9\n",
      "Accuracy: 0.5367\n"
     ]
    }
   ],
   "source": [
    "sample = [\"r2p3\", \"r6p7\", \"r6p8\",\"r6p9\",\"r1p9\"]\n",
    "arb = False\n",
    "\n",
    "\n",
    "for m in sample:\n",
    "    for arb in [True,False]:\n",
    "    # load model\n",
    "        if arb:\n",
    "            channel = 1\n",
    "            model = torch.load(f\"CNN_no_filter_{m}_arb.pt\", map_location=torch.device('cpu'))\n",
    "            print(f\"Running ARB {m}\")\n",
    "        else:\n",
    "            channel = 0\n",
    "            model = torch.load(f\"CNN_no_filter_{m}.pt\", map_location=torch.device('cpu'))\n",
    "            print(f\"Running MTJ {m}\")\n",
    "\n",
    "        path = f\"waveforms_{m}_fast_test/\"\n",
    "\n",
    "        file_list = os.listdir(path)\n",
    "        file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "        dataset = SpeechDataset(path = path, file_list=file_list, ch=channel)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "        test_model(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note  \n",
    "MTJ - ARB\n",
    "\n",
    "# r6p8 no filter\n",
    "0.5467 - 0.72000\n",
    "\n",
    "# r6p8 #  filtered\n",
    "0.8100-0.6867\n",
    "\n",
    "# r1p9  filtered\n",
    "0.6267 - 0.8300\n",
    "\n",
    "# r2p3 filtered\n",
    "0.7767 - 0.8367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5999999999999943"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55.7-59.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
