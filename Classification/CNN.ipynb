{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from RSRTxReadBin.RTxReadBin import RTxReadBin\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions and classes\n",
    "# Custom Dataset\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, path = \"waveforms_r6p8_fast/\", file_list=[], ch=0, n_mels=64, n_fft=2048, hop_length=512):\n",
    "        self.file_list = file_list\n",
    "        self.ch = ch\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.path = path\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = self.load_waveform(file_path, self.ch)\n",
    "        mel_spectrogram = self.transform_audio(waveform, sample_rate) # No use the spectrogram\n",
    "        label = self.get_label_from_filename(file_path)\n",
    "        return mel_spectrogram, label\n",
    "\n",
    "    def load_waveform(self, file_path, ch):\n",
    "        wfm_data, b, meta_data = RTxReadBin(self.path+file_path, nNofChannels=2)\n",
    "        wfm_data = np.array(wfm_data[:, 0, ch])[:int(len(wfm_data[:, 0, ch]) / 2)]\n",
    "        sample_rate = int(1 / meta_data[\"Resolution\"])\n",
    "        waveform = torch.from_numpy(wfm_data).float()\n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def transform_audio(self, waveform, sample_rate):\n",
    "        transform = transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=self.n_mels, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        mel_spectrogram = transform(waveform.unsqueeze(0))\n",
    "        return mel_spectrogram\n",
    "\n",
    "    def get_label_from_filename(self, filename):\n",
    "        return int(os.path.basename(filename).split('_')[0])\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        device = next(model.parameters()).device\n",
    "        print(device)\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        \n",
    "# Training Function\n",
    "def train_model_cp(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        device = next(model.parameters()).device\n",
    "        print(device)\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "        torch.save(model, f\"r1p9_checkpoint/CNN_filter_r1p9_softmax_arb_e{epoch}_loss{epoch_loss:.2f}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [04:44<1:53:40, 284.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 1.7577\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [09:07<1:44:13, 271.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.3237\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [13:37<1:39:26, 271.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.0962\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [18:07<1:34:38, 270.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 0.9962\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [22:43<1:30:49, 272.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 0.8920\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [27:13<1:26:00, 271.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 0.7845\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [31:48<1:21:53, 272.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 0.7783\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [35:49<1:14:24, 262.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 0.6986\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [39:48<1:08:06, 255.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 0.6598\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [43:34<1:01:30, 246.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.6263\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [47:24<56:18, 241.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.6663\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [51:05<50:55, 235.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.6039\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [54:56<46:48, 234.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.5788\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [58:35<42:03, 229.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.5489\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [1:02:31<38:33, 231.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.5284\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [1:06:26<34:51, 232.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.5485\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [1:10:36<31:41, 237.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.4993\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:14:52<28:22, 243.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.5045\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:18:59<24:26, 244.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.5475\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:22:57<20:12, 242.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.5303\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [1:26:47<15:55, 238.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.5035\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [1:30:45<11:55, 238.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.4961\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [1:34:57<08:04, 242.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.4646\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [1:39:30<04:11, 251.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.5133\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:44:17<00:00, 250.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r6p8 model on MTJ ##\n",
    "\n",
    "# Network Definition\n",
    "class LargerSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=1):\n",
    "        super(LargerSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 1 * 1, 64)  # Adjusted input size for fc1\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x = self.pool(x)\n",
    "        #x = F.relu(self.conv3(x))\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r6p8_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r6p8_arb2.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"CNN_filter_r6p8_arb2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## r6p8 model on ARB ##\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Network Definition\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSmallSpeechCNN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28msuper\u001b[39m(SmallSpeechCNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "## r6p8 model on ARB ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r6p8_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r6p8_softmax_arb.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [06:58<2:47:16, 418.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 2.2146\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [12:22<2:19:05, 362.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 2.1184\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [17:39<2:05:24, 342.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 2.0895\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [23:01<1:56:55, 334.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 2.0615\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [28:19<1:49:23, 328.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 2.0559\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [33:55<1:44:49, 331.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 2.0064\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [39:22<1:38:52, 329.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 1.9877\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [44:48<1:33:03, 328.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 1.9563\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [50:02<1:26:23, 323.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 1.9315\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [55:35<1:21:40, 326.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 1.9177\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [1:01:09<1:16:44, 328.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 1.9002\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [1:06:33<1:10:59, 327.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 1.8868\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [1:12:09<1:06:01, 330.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 1.8851\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [1:17:36<1:00:21, 329.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 1.8843\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [1:23:00<54:33, 327.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 1.8705\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [1:28:27<49:05, 327.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 1.8617\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [1:33:50<43:28, 326.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 1.8506\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:39:13<37:55, 325.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 1.8405\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:44:41<32:35, 325.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 1.8458\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:50:00<27:00, 324.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 1.8391\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [1:55:30<21:42, 325.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 1.8320\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [2:00:50<16:11, 323.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 1.8395\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [2:06:23<10:53, 326.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 1.8285\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [2:12:03<05:30, 330.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 1.8206\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [2:17:46<00:00, 330.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 1.8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r1p9 model on MTJ ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.003 # 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r1p9_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=0)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r1p9_softmax_2.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]c:\\Users\\olive\\AppData\\Local\\anaconda3\\envs\\Pythonny\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (1025) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [06:53<2:45:28, 413.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 2.1108\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [12:38<2:22:57, 372.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.2493\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [18:30<2:13:13, 363.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.0264\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [24:23<2:05:51, 359.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 0.9570\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [30:33<2:01:02, 363.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 0.9610\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [36:05<1:51:39, 352.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 0.8811\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [41:47<1:44:44, 349.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 0.9236\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [47:35<1:38:48, 348.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 0.8132\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [53:31<1:33:37, 351.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 0.8330\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [59:08<1:26:40, 346.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.8208\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [1:05:29<1:23:19, 357.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.7876\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [1:12:12<1:20:24, 371.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.7765\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [1:18:23<1:14:14, 371.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.8332\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [1:24:28<1:07:41, 369.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.8178\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [1:30:32<1:01:18, 367.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 1.5609\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [1:36:21<54:18, 362.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.9822\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [1:42:06<47:34, 356.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 1.0652\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:48:06<41:44, 357.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.7800\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:53:52<35:25, 354.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.7996\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [2:00:02<29:55, 359.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.8152\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [2:05:24<23:12, 348.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.7213\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [2:11:20<17:31, 350.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.7267\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [2:17:13<11:41, 350.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.7665\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [2:23:06<05:51, 351.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.7583\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [2:28:51<00:00, 357.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.7203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r1p9 model on ARB ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r1p9_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r1p9_softmax_arb.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [07:30<3:00:09, 450.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 2.1928\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [13:12<2:28:17, 386.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.6142\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [18:53<2:14:09, 365.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.5078\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [24:33<2:04:27, 355.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 1.4442\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [30:02<1:55:23, 346.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 1.3782\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [35:46<1:49:21, 345.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 1.2641\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [41:19<1:42:22, 341.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 1.1806\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [47:15<1:37:59, 345.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 1.1269\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [52:30<1:29:39, 336.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 1.0844\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [58:25<1:25:33, 342.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 1.0549\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [1:04:05<1:19:40, 341.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 1.0342\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [1:09:50<1:14:13, 342.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 1.0134\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [1:15:14<1:07:21, 336.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.9925\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [1:21:04<1:02:30, 340.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.9675\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [1:27:00<57:32, 345.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.9287\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [1:32:33<51:15, 341.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.9131\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [1:38:13<45:30, 341.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.8666\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:43:33<39:02, 334.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.8525\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:49:32<34:12, 342.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.8340\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:55:18<28:36, 343.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.8140\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [2:01:02<22:53, 343.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.8040\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [2:07:04<17:27, 349.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.7777\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [2:12:49<11:35, 347.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.7530\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [2:18:50<05:51, 351.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.7446\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [2:24:57<00:00, 347.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r2p3 model on MTJ ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r2p3_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=0)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r2p3_softmax.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [06:04<2:25:39, 364.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 1.8978\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [11:21<2:09:04, 336.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.3647\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [17:00<2:03:48, 337.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.1094\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [23:14<2:03:15, 352.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 1.0869\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [29:05<1:57:15, 351.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 0.9756\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [35:06<1:52:18, 354.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 0.9458\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [41:02<1:46:33, 355.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 1.0628\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [46:53<1:40:14, 353.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 0.9662\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [52:55<1:35:02, 356.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 1.0264\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [58:55<1:29:22, 357.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.8357\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [1:04:51<1:23:18, 357.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.9960\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [1:10:26<1:15:54, 350.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.8285\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [1:16:33<1:11:05, 355.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.7566\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [1:22:15<1:04:25, 351.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.7177\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [1:28:11<58:47, 352.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.7586\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [1:34:07<53:02, 353.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.6750\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [1:39:46<46:33, 349.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.6198\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:45:47<41:10, 352.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.8541\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:51:35<35:08, 351.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.7413\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:57:32<29:25, 353.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.8684\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [2:03:16<23:20, 350.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.6254\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [2:09:02<17:27, 349.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.6146\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [2:14:40<11:31, 345.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.6249\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [2:20:24<05:45, 345.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.5714\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [2:26:12<00:00, 350.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.5661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r2p3 model on ARB ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r2p3_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r2p3_softmax_arb.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [03:24<1:21:53, 204.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 1.9182\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [06:46<1:17:46, 202.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.3432\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [10:12<1:14:56, 204.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.1525\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [13:37<1:11:36, 204.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 1.0313\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [17:01<1:08:04, 204.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 0.9612\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [20:26<1:04:50, 204.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 0.8777\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [23:52<1:01:34, 205.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 0.8147\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [27:15<57:54, 204.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 0.7841\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [30:38<54:25, 204.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 0.7253\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [34:03<51:03, 204.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.6967\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [37:26<47:33, 203.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.6603\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [40:52<44:18, 204.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.6219\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [44:19<41:04, 205.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.5970\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [47:45<37:39, 205.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.5802\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [51:13<34:21, 206.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.5513\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [54:39<30:56, 206.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.5314\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [58:03<27:24, 205.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.5172\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:01:29<23:59, 205.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.4943\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:04:53<20:31, 205.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.4709\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:08:20<17:08, 205.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.4488\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [1:11:47<13:44, 206.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.4493\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [1:15:12<10:17, 205.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.4354\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [1:18:38<06:51, 205.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.4142\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [1:22:05<03:26, 206.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.4157\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:25:31<00:00, 205.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r6p7 model on MTJ ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r6p7_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=0)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r6p7_softmax.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [04:44<1:53:53, 284.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 1.8379\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [08:08<1:30:59, 237.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.4107\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [11:29<1:20:52, 220.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.4102\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [14:51<1:14:40, 213.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 1.1168\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [18:16<1:10:06, 210.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 1.0005\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [21:40<1:05:55, 208.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 1.0304\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [25:02<1:01:49, 206.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 0.8085\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [28:27<58:19, 205.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 0.8018\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [31:52<54:46, 205.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 0.9800\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [35:14<51:07, 204.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.8696\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [38:39<47:44, 204.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.7472\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [42:02<44:13, 204.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.6342\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [45:25<40:45, 203.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.6231\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [48:50<37:24, 204.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.6641\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [52:13<33:59, 203.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.6917\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [55:38<30:37, 204.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.5546\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [59:04<27:17, 204.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.6172\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:02:32<23:59, 205.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.7151\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:06:00<20:38, 206.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.5417\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:09:24<17:08, 205.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.6276\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [1:12:48<13:40, 205.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.5075\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [1:16:11<10:13, 204.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.6891\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [1:19:39<06:50, 205.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.6990\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [1:23:03<03:25, 205.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.4941\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:26:29<00:00, 207.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.5580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r6p7 model on ARB ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r6p7_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r6p7_softmax_arb.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [04:53<1:57:12, 293.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 1.8562\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [09:11<1:44:28, 272.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.2670\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [12:29<1:27:30, 238.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.0976\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [15:51<1:18:25, 224.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 1.0007\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [19:33<1:14:25, 223.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 0.8826\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [22:54<1:08:20, 215.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 0.8128\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [26:19<1:03:41, 212.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 0.7625\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [30:01<1:01:01, 215.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 0.6936\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [33:23<56:17, 211.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 0.6730\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [36:50<52:30, 210.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.6434\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [40:35<50:04, 214.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.6157\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [44:28<47:40, 220.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.5833\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [47:55<43:12, 216.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.5487\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [51:40<40:07, 218.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.5373\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [55:34<37:15, 223.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.5063\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [59:26<33:52, 225.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.4736\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [1:03:01<29:41, 222.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.4629\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:06:25<25:20, 217.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.4372\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:09:48<21:17, 212.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.4357\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:13:10<17:27, 209.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.4087\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [1:16:35<13:52, 208.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.4055\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [1:19:53<10:15, 205.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.3890\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [1:23:10<06:45, 202.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.3724\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [1:26:23<03:19, 199.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.3735\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:29:36<00:00, 215.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r6p9 model on MTJ ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r6p9_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=0)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r6p9_softmax.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\AppData\\Local\\anaconda3\\envs\\Pythonny\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (1025) may be set too low.\n",
      "  warnings.warn(\n",
      "  4%|▍         | 1/25 [03:11<1:16:27, 191.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24, Loss: 1.7049\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [06:20<1:12:53, 190.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24, Loss: 1.2852\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [09:44<1:11:57, 196.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24, Loss: 1.1393\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [13:09<1:09:55, 199.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24, Loss: 1.0731\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [16:32<1:07:02, 201.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24, Loss: 0.9604\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [19:55<1:03:48, 201.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24, Loss: 0.9225\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [23:20<1:00:50, 202.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24, Loss: 0.8903\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [26:45<57:38, 203.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24, Loss: 1.0184\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [30:10<54:24, 204.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24, Loss: 0.8460\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [33:35<51:06, 204.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24, Loss: 0.8435\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [36:59<47:38, 204.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24, Loss: 0.8399\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [40:25<44:20, 204.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24, Loss: 0.7624\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [43:47<40:47, 203.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24, Loss: 0.7354\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [47:08<37:12, 202.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24, Loss: 0.7076\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [50:29<33:44, 202.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24, Loss: 0.7925\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [53:50<30:16, 201.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24, Loss: 0.7633\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [57:11<26:53, 201.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24, Loss: 0.6229\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [1:00:33<23:33, 201.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24, Loss: 0.6326\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [1:03:57<20:15, 202.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24, Loss: 0.6717\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [1:07:21<16:54, 202.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24, Loss: 0.6379\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [1:10:45<13:32, 203.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24, Loss: 0.5717\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [1:14:09<10:10, 203.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24, Loss: 0.5835\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [1:17:30<06:45, 202.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24, Loss: 0.5421\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [1:20:52<03:22, 202.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24, Loss: 0.5588\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:24:15<00:00, 202.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24, Loss: 0.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## r6p9 model on ARB ##\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(batch_size, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=9, stride=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(64, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        #x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Paths and Data\n",
    "path = \"waveforms_r6p9_fast/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Saving and loading the model\n",
    "torch.save(model, \"CNN_filter_r6p9_softmax_arb.pt\")\n",
    "#model = torch.load(\"CNN_first_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\AppData\\Local\\anaconda3\\envs\\Pythonny\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (1025) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "# Test loop for model\n",
    "\n",
    "model = torch.load(\"CNN_filter_r6p8_arb2.pt\")\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "path = \"waveforms_r6p8_fast_test/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "test_model(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/24, Loss: 2.3040\n",
      "cuda:0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Load packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from RSRTxReadBin.RTxReadBin import RTxReadBin\n",
    "import pandas as pd\n",
    "\n",
    "# Custom Dataset\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, file_list, ch=0, n_mels=128, n_fft=2048, hop_length=512):\n",
    "        self.file_list = file_list\n",
    "        self.ch = ch\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, sample_rate = self.load_waveform(file_path, self.ch)\n",
    "        label = self.get_label_from_filename(file_path)\n",
    "        return waveform, label\n",
    "\n",
    "    def load_waveform(self, file_path, ch):\n",
    "        wfm_data, b, meta_data = RTxReadBin(\"waveforms_r6p8_fast/\"+file_path, nNofChannels=2)\n",
    "        wfm_data = np.array(wfm_data[:, 0, ch])[:int(len(wfm_data[:, 0, ch]) / 2)]\n",
    "        sample_rate = int(1 / meta_data[\"Resolution\"])\n",
    "        waveform = torch.from_numpy(wfm_data).float()\n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def transform_audio(self, waveform, sample_rate):\n",
    "        transform = transforms.MelSpectrogram(sample_rate=sample_rate, n_mels=self.n_mels, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        mel_spectrogram = transform(waveform.unsqueeze(0))\n",
    "        return mel_spectrogram\n",
    "\n",
    "    def get_label_from_filename(self, filename):\n",
    "        return int(os.path.basename(filename).split('_')[0])\n",
    "\n",
    "# Network Definition\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(batch_size, 16, kernel_size=12, stride=6, padding=0)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=12, stride=6, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(9258, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(1, 8, -1)\n",
    "        #print(\"Input:\", x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (batch_size, int(9258)))\n",
    "        x = x.squeeze(0)\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        # x = x.view(-1, 32 * 1 * 1)  # Adjusted input size for fc1\n",
    "        print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(\"FC2\", x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        device = next(model.parameters()).device\n",
    "        print(device)\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Paths and Data\n",
    "file_list = os.listdir(\"waveforms_r6p8_fast\")\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(file_list)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SmallSpeechCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 25\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "device= \"cpu\"\n",
    "\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(32 * 1 * 1, 128, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(\"Covn1\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"Pool\", x.shape)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        #print(\"Adaptive Pool\", x.shape)\n",
    "        x = x.view(-1, 32 * 1 * 1)  # Adjusted input size for fc1\n",
    "        #print(\"View\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"FC1\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"FC2\", x.shape)\n",
    "        return x\n",
    "\n",
    "model = SmallSpeechCNN(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11322"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8967\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make confusion matrix\n",
    "\n",
    "model = torch.load(\"CNN_filter_r6p9_softmax.pt\")\n",
    "path = \"waveforms_r6p9_fast_test/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list = [file for file in file_list if file.endswith('.Wfm.bin')]\n",
    "dataset = SpeechDataset(path = path, file_list=file_list, ch=0)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "running_corrects = 0\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    true_labels.append(labels.cpu())\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    pred_labels.append(preds.cpu())\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0  0  1  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  1  0  0  0  0  1]\n",
      " [ 1  0 19  5  0  0  4  0  1  0]\n",
      " [ 0  0  3 26  0  0  1  0  0  0]\n",
      " [ 0  1  0  0 29  0  0  0  0  0]\n",
      " [ 0  2  0  0  0 27  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 28  2  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  0  2  0  0  0  2  0 26  0]\n",
      " [ 2  1  0  0  0  0  0  0  0 27]]\n",
      "figure saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(cm)\n",
    "cm = cm/cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.matshow(cm, fignum=0, cmap='inferno')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(range(10), labels=[str(i) for i in range(10)])\n",
    "plt.yticks(range(10), labels=[str(i) for i in range(10)])\n",
    "print(\"figure saved\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../Dropbox/Apps/Overleaf/Speciale/Chapter5_application/fig/confmat_r6p9_cnn.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "cm = np.round(cm/cm.sum(axis=1)[:, np.newaxis]*100, decimals=0).astype(int)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='inferno', xticklabels=[str(i) for i in range(10)], yticklabels=[str(i) for i in range(10)])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../Dropbox/Apps/Overleaf/Speciale/Chapter5_application/fig/confmat_r6p9_cnn.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (2400, 48, 48)\n",
      "Test set size: (600, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "def load_wav_files(directory):\n",
    "    \"\"\"Load all .wav files from a directory and return their paths.\"\"\"\n",
    "    wav_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_files.append(os.path.join(root, file))\n",
    "    return wav_files\n",
    "\n",
    "def pad_features(features, max_len=48):\n",
    "    \"\"\"Pad features to ensure they all have the same shape.\"\"\"\n",
    "    padded_features = []\n",
    "    for feature in features:\n",
    "        if feature.shape[1] < max_len:\n",
    "            pad_width = max_len - feature.shape[1]\n",
    "            padded_feature = np.pad(feature, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            padded_feature = feature[:, :max_len]\n",
    "        padded_features.append(padded_feature)\n",
    "    return np.array(padded_features)\n",
    "\n",
    "def extract_features(file_path, n_mels=48, n_fft=256, hop_length=64):\n",
    "    \"\"\"Extract Mel spectrogram features from an audio file.\"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram\n",
    "\n",
    "def create_dataset(file_paths):\n",
    "    \"\"\"Create dataset from a list of file paths.\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        label = os.path.basename(file_path).split('_')[0]  # Assuming directory name is the label\n",
    "        features.append(extract_features(file_path))\n",
    "        labels.append(float(label))\n",
    "    features = pad_features(features, max_len=48)\n",
    "    return np.array(features), torch.LongTensor(labels)\n",
    "\n",
    "def split_dataset(features, labels, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split the dataset into training and test sets.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage\n",
    "directory = '../../Simulations/FSDD/recordings/'\n",
    "wav_files = load_wav_files(directory)\n",
    "features, labels = create_dataset(wav_files)\n",
    "X_train, X_test, y_train, y_test = split_dataset(features, labels)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "   train_data.append([X_train[i], y_train[i]])\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader([X_test, y_test], batch_size=1, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class SmallSpeechCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SmallSpeechCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(-1, 64)  # Adjusted input size for fc1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "num_classes = 10\n",
    "model = SmallSpeechCNN(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:21<08:39, 21.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.5146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [01:03<12:45, 33.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [01:54<15:11, 41.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.5585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [02:43<15:32, 44.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [03:38<16:06, 48.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [05:22<21:15, 67.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [06:31<20:22, 67.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [07:35<18:51, 66.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [08:33<17:05, 64.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.8166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [09:26<15:06, 60.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.8637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [10:20<13:41, 58.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [11:28<13:20, 61.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [12:30<12:20, 61.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [13:35<11:26, 62.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [14:45<10:48, 64.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.2609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [15:39<09:13, 61.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [16:39<08:09, 61.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [17:38<07:03, 60.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [18:48<06:19, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.4357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [19:56<05:24, 64.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.7235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [21:05<04:24, 66.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [22:06<03:13, 64.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [23:10<02:08, 64.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [24:18<01:05, 65.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [25:26<00:00, 61.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.4311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 25\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f' Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 29.67%\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "   test_data.append([X_test[i], y_test[i]])\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw on 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_9888\\2742448426.py:105: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "  4%|▍         | 1/25 [00:19<07:53, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:43<08:29, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.3089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [01:01<07:21, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [01:18<06:41, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.8404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [01:36<06:13, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 2.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [01:53<05:45, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [02:10<05:16, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.5187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [02:27<04:55, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [02:44<04:36, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [03:01<04:17, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.4832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [03:18<03:59, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.3946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [03:35<03:41, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [03:52<03:25, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [04:07<03:03, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [04:24<02:45, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [04:41<02:31, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [05:00<02:18, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [05:20<02:07, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [05:41<01:54, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [06:00<01:35, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [06:18<01:14, 18.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [06:35<00:54, 18.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [06:50<00:34, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [07:06<00:16, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 1.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [07:21<00:00, 17.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Load packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#import torchaudio\n",
    "#import torchaudio.transforms as transforms\n",
    "import os \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from RSRTxReadBin.RTxReadBin import RTxReadBin\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_wav_files(directory):\n",
    "    \"\"\"Load all .wav files from a directory and return their paths.\"\"\"\n",
    "    wav_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                wav_files.append(os.path.join(root, file))\n",
    "    return wav_files\n",
    "\n",
    "def pad_features(features, max_len=20_000):\n",
    "    \"\"\"Pad features to ensure they all have the same shape.\"\"\"\n",
    "    padded_features = []\n",
    "    for feature in features:\n",
    "        if feature.shape[0] < max_len:\n",
    "            pad_width = max_len - feature.shape[0]\n",
    "            padded_feature = np.concatenate((feature, np.zeros((pad_width,))), axis=0)\n",
    "        else:\n",
    "            padded_feature = feature[:max_len]\n",
    "        padded_features.append(padded_feature)\n",
    "    return padded_features\n",
    "\n",
    "def extract_features(file_path, n_mels=2, n_fft=400, hop_length=100):\n",
    "    \"\"\"Extract Mel spectrogram features from an audio file.\"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return y\n",
    "\n",
    "def create_dataset(file_paths):\n",
    "    \"\"\"Create dataset from a list of file paths.\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        label = os.path.basename(file_path).split('_')[0]  # Assuming directory name is the label\n",
    "        features.append(extract_features(file_path))\n",
    "        labels.append(float(label))\n",
    "    features = pad_features(features, max_len=20_000)\n",
    "    return torch.FloatTensor(features), torch.LongTensor(labels)\n",
    "\n",
    "def split_dataset(features, labels, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split the dataset into training and test sets.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=10, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "        #print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.pool1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        #print(x.shape)\n",
    "        x = x.squeeze(0)\n",
    "        #print(x.shape)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "num_classes = 10\n",
    "model = M5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Load the data\n",
    "wav_files = load_wav_files(directory)\n",
    "features, labels = create_dataset(wav_files)\n",
    "X_train, X_test, y_train, y_test = split_dataset(features, labels)\n",
    "\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "   train_data.append([X_train[i], y_train[i]])\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f' Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_9888\\2742448426.py:105: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 23.50%\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "   test_data.append([X_test[i], y_test[i]])\n",
    "   \n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D RAW perplexity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2859244089821975\n",
      "Epoch 2, Loss: 2.063128501748045\n",
      "Epoch 3, Loss: 1.475513486340642\n",
      "Epoch 4, Loss: 0.940098247746937\n",
      "Epoch 5, Loss: 0.6277096534015921\n",
      "Epoch 6, Loss: 0.44645222392651096\n",
      "Epoch 7, Loss: 0.36851257104751617\n",
      "Epoch 8, Loss: 0.2934026506636292\n",
      "Epoch 9, Loss: 0.24970499827296105\n",
      "Epoch 10, Loss: 0.20073409864847538\n",
      "Epoch 11, Loss: 0.16480187290657947\n",
      "Epoch 12, Loss: 0.15049739569190934\n",
      "Epoch 13, Loss: 0.12754700377077824\n",
      "Epoch 14, Loss: 0.13214848122051384\n",
      "Epoch 15, Loss: 0.1027525710175261\n",
      "Epoch 16, Loss: 0.10326874512389016\n",
      "Epoch 17, Loss: 0.08621267641078778\n",
      "Epoch 18, Loss: 0.06518357026202201\n",
      "Epoch 19, Loss: 0.07490987221287165\n",
      "Epoch 20, Loss: 0.0739372280461608\n",
      "Epoch 21, Loss: 0.05871218545540955\n",
      "Epoch 22, Loss: 0.0547832888756146\n",
      "Epoch 23, Loss: 0.05166757200635994\n",
      "Epoch 24, Loss: 0.03634893684611901\n",
      "Epoch 25, Loss: 0.0640799388902856\n",
      "Epoch 26, Loss: 0.04993362226264054\n",
      "Epoch 27, Loss: 0.04007630175009775\n",
      "Epoch 28, Loss: 0.042995033216000754\n",
      "Epoch 29, Loss: 0.03728016178692272\n",
      "Epoch 30, Loss: 0.03458367179818291\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Preprocess audio function\n",
    "def preprocess_audio(file_path, target_sr=20000):\n",
    "    y, sr = librosa.load(directory+file_path, sr=8000)\n",
    "    if len(y) < target_sr:\n",
    "        y = np.pad(y, (0, target_sr - len(y)))\n",
    "    else:\n",
    "        y = y[:target_sr]\n",
    "    return y\n",
    "\n",
    "# Custom Dataset\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        audio_data = preprocess_audio(file_path)\n",
    "        if self.transform:\n",
    "            audio_data = self.transform(audio_data)\n",
    "        return torch.tensor(audio_data, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define the M5 model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=10, stride=3, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=5, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(0)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.squeeze(0)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example usage\n",
    "directory = '../../Simulations/FSDD/recordings/'\n",
    "file_paths = os.listdir(directory)  # Replace with your file paths\n",
    "\n",
    "#Split filepath to train and test randomly\n",
    "file_paths_train, file_paths_test = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
    "labels_train = [int(os.path.basename(file_path).split('_')[0]) for file_path in file_paths_train]\n",
    "labels_test = [int(os.path.basename(file_path).split('_')[0]) for file_path in file_paths_test]\n",
    "\n",
    "dataset = AudioDataset(file_paths_train, labels_train)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = M5(n_input=1, n_output=10)  # Adjust n_input based on your preprocessing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.unsqueeze(1)  # Add channel dimension\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.090507688522339\n",
      "Accuracy: 37.83%\n",
      "Epoch 2, Loss: 1.7708391014734903\n",
      "Accuracy: 9.33%\n",
      "Epoch 3, Loss: 1.4898724873860678\n",
      "Accuracy: 11.17%\n",
      "Epoch 4, Loss: 1.2882515716552734\n",
      "Accuracy: 27.17%\n",
      "Epoch 5, Loss: 1.1093785651524861\n",
      "Accuracy: 9.33%\n",
      "Epoch 6, Loss: 0.9687022272745768\n",
      "Accuracy: 21.50%\n",
      "Epoch 7, Loss: 0.8598426802953084\n",
      "Accuracy: 11.17%\n",
      "Epoch 8, Loss: 0.7739162127176921\n",
      "Accuracy: 9.33%\n",
      "Epoch 9, Loss: 0.6800057991345724\n",
      "Accuracy: 16.67%\n",
      "Epoch 10, Loss: 0.6284170587857564\n",
      "Accuracy: 37.17%\n",
      "Epoch 11, Loss: 0.5366672039031982\n",
      "Accuracy: 23.17%\n",
      "Epoch 12, Loss: 0.4995364995797475\n",
      "Accuracy: 14.67%\n",
      "Epoch 13, Loss: 0.472200741370519\n",
      "Accuracy: 30.83%\n",
      "Epoch 14, Loss: 0.42357081174850464\n",
      "Accuracy: 9.83%\n",
      "Epoch 15, Loss: 0.39550186475118\n",
      "Accuracy: 9.50%\n",
      "Epoch 16, Loss: 0.3587249968449275\n",
      "Accuracy: 18.50%\n",
      "Epoch 17, Loss: 0.31505261520544686\n",
      "Accuracy: 16.00%\n",
      "Epoch 18, Loss: 0.31730391760667165\n",
      "Accuracy: 10.17%\n",
      "Epoch 19, Loss: 0.277662522594134\n",
      "Accuracy: 11.00%\n",
      "Epoch 20, Loss: 0.23883523215850194\n",
      "Accuracy: 17.00%\n",
      "Epoch 21, Loss: 0.23934648424386978\n",
      "Accuracy: 9.50%\n",
      "Epoch 22, Loss: 0.2097884398698807\n",
      "Accuracy: 26.50%\n",
      "Epoch 23, Loss: 0.22277644137541452\n",
      "Accuracy: 29.17%\n",
      "Epoch 24, Loss: 0.21067575265963873\n",
      "Accuracy: 24.50%\n",
      "Epoch 25, Loss: 0.17488377233346303\n",
      "Accuracy: 9.67%\n",
      "Epoch 26, Loss: 0.20051345030466716\n",
      "Accuracy: 9.50%\n",
      "Epoch 27, Loss: 0.15989219794670742\n",
      "Accuracy: 9.83%\n",
      "Epoch 28, Loss: 0.1530694417655468\n",
      "Accuracy: 55.83%\n",
      "Epoch 29, Loss: 0.17998487909634908\n",
      "Accuracy: 16.50%\n",
      "Epoch 30, Loss: 0.12936924497286478\n",
      "Accuracy: 32.17%\n"
     ]
    }
   ],
   "source": [
    "# Multi batch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocess audio function\n",
    "def preprocess_audio(file_path, target_sr=20000):\n",
    "    y, sr = librosa.load(directory + file_path, sr=8000)\n",
    "    if len(y) < target_sr:\n",
    "        y = np.pad(y, (0, target_sr - len(y)))\n",
    "    else:\n",
    "        y = y[:target_sr]\n",
    "    return y\n",
    "\n",
    "# Custom Dataset\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        audio_data = preprocess_audio(file_path)\n",
    "        if self.transform:\n",
    "            audio_data = self.transform(audio_data)\n",
    "        return torch.tensor(audio_data, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Define the M5 model\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=10, stride=3, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=5, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.squeeze(1)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example usage\n",
    "directory = '../../Simulations/FSDD/recordings/'\n",
    "file_paths = os.listdir(directory)  # Replace with your file paths\n",
    "\n",
    "# Split filepath to train and test randomly\n",
    "file_paths_train, file_paths_test = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
    "labels_train = [int(os.path.basename(file_path).split('_')[0]) for file_path in file_paths_train]\n",
    "labels_test = [int(os.path.basename(file_path).split('_')[0]) for file_path in file_paths_test]\n",
    "\n",
    "dataset = AudioDataset(file_paths_train, labels_train)\n",
    "\n",
    "# Update DataLoader to use batch size of 32\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = M5(n_input=1, n_output=10)  # Adjust n_input based on your preprocessing\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.unsqueeze(1)  # Add channel dimension\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")\n",
    "    \n",
    "    # Test the model while running the loop\n",
    "    test_dataset = AudioDataset(file_paths_test, labels_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# Write the test loop\n",
    "test_dataset = AudioDataset(file_paths_test, labels_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pythonny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
